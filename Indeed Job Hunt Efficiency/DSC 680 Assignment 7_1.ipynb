{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 680\n",
    "## Assignment 8.1\n",
    "## Chase Lemons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indeed_job_dataset.csv\", sep =\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Queried_Salary</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Skill</th>\n",
       "      <th>No_of_Skills</th>\n",
       "      <th>Company</th>\n",
       "      <th>No_of_Reviews</th>\n",
       "      <th>No_of_Stars</th>\n",
       "      <th>...</th>\n",
       "      <th>MD</th>\n",
       "      <th>DC</th>\n",
       "      <th>NC</th>\n",
       "      <th>Other_states</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Other_industries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6a105f495c36a...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['SAP', 'SQL']</td>\n",
       "      <td>2</td>\n",
       "      <td>Express Scripts</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=86afd561ea8c6...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Machine Learning', 'R', 'SAS', 'SQL', 'Python']</td>\n",
       "      <td>5</td>\n",
       "      <td>Money Mart Financial Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e0aad317e6d45...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Data Mining', 'Data Management', 'R', 'SAS',...</td>\n",
       "      <td>9</td>\n",
       "      <td>comScore</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Graduate Studies Program - Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Certified Internal Auditor']</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>158.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fec647775a21e...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Statistical Software', 'Time Management', 'R...</td>\n",
       "      <td>7</td>\n",
       "      <td>Federal Reserve Bank of Dallas</td>\n",
       "      <td>495.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  Job_Title  \\\n",
       "0           0                             Data Scientist   \n",
       "1           1                             Data Scientist   \n",
       "2           2                             Data Scientist   \n",
       "3           3  Graduate Studies Program - Data Scientist   \n",
       "4           4                           Data Scientist I   \n",
       "\n",
       "                                                Link Queried_Salary  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=6a105f495c36a...         <80000   \n",
       "1  https://www.indeed.com/rc/clk?jk=86afd561ea8c6...         <80000   \n",
       "2  https://www.indeed.com/rc/clk?jk=e0aad317e6d45...         <80000   \n",
       "3  https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...         <80000   \n",
       "4  https://www.indeed.com/rc/clk?jk=fec647775a21e...         <80000   \n",
       "\n",
       "         Job_Type                                              Skill  \\\n",
       "0  data_scientist                                     ['SAP', 'SQL']   \n",
       "1  data_scientist  ['Machine Learning', 'R', 'SAS', 'SQL', 'Python']   \n",
       "2  data_scientist  ['Data Mining', 'Data Management', 'R', 'SAS',...   \n",
       "3  data_scientist                     ['Certified Internal Auditor']   \n",
       "4  data_scientist  ['Statistical Software', 'Time Management', 'R...   \n",
       "\n",
       "   No_of_Skills                         Company  No_of_Reviews  No_of_Stars  \\\n",
       "0             2                 Express Scripts         3301.0          3.3   \n",
       "1             5   Money Mart Financial Services            NaN          NaN   \n",
       "2             9                        comScore           62.0          3.5   \n",
       "3             1     Central Intelligence Agency          158.0          4.3   \n",
       "4             7  Federal Reserve Bank of Dallas          495.0          4.1   \n",
       "\n",
       "         ...         MD DC NC Other_states Consulting and Business Services  \\\n",
       "0        ...          0  0  0            1                                0   \n",
       "1        ...          0  0  0            0                                0   \n",
       "2        ...          0  0  0            1                                0   \n",
       "3        ...          0  1  0            0                                0   \n",
       "4        ...          0  0  0            0                                0   \n",
       "\n",
       "  Internet and Software  Banks and Financial Services  Health Care  Insurance  \\\n",
       "0                     0                             0            1          0   \n",
       "1                     0                             0            0          0   \n",
       "2                     0                             0            0          0   \n",
       "3                     0                             0            0          0   \n",
       "4                     0                             1            0          0   \n",
       "\n",
       "   Other_industries  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chase H. Lemons\n",
      "\n",
      "\tAdvanced Analyst  \n",
      "\n",
      "\t509.668.8358  \n",
      "\n",
      "\tClemons_12@hotmail.com\n",
      "\n",
      "\tGoal oriented professional with 5+ years of experience in big data and advanced analytics across multiple functions. Seeking a position to utilize and enhance my leadership, analytics and developer skills. Extremely passionate about analytics, strategy and process improvement.\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Work Experience:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sr. Advanced Analyst | Textron Aviation\t            \t\t\t\t         October 2018 - Present\n",
      "\n",
      "â€¢ Actively provide strategy for overall analytics roadmap and operating model for Textron Aviation.\n",
      "\n",
      "â€¢ Lead a Tableau proof of concept with the business.\n",
      "\n",
      "â€¢ Develop dashboards for multiple business areas utilizing Tableau, Qlikview, and Power BI.\n",
      "\n",
      "â€¢ Ensure ETL processes in and out of the enterprise data warehouse perform successfully. \n",
      "\n",
      "â€¢ Uses a combination of R, Python and SQL for data manipulation, analysis and reporting daily.\n",
      "\n",
      "â€¢ Implemented a model to identify parts that needed price adjustment based on ecommerce data.\n",
      "\n",
      "â€¢ Translates high-level business requirements into functional specifications and manages changes.\n",
      "\n",
      "â€¢ Develop metrics of utilization of IT tools and systems.\n",
      "\n",
      "â€¢ Team lead for business intelligence and predictive data models.\n",
      "\n",
      "â€¢ Developed a candidate percent match tool for recruiters to help with efficiency.\n",
      "\n",
      "\n",
      "\n",
      "HR Analyst | Textron Aviation\t           \t\t           Dec 2015 â€“ February 2016, January 2017 - Present\n",
      "\n",
      "â€¢ Be a lead for team members with less experience in the analytics space.\n",
      "\n",
      "â€¢ Perform technology overviews and provide recommendations on BI, Analytics tools, and other HR tools.\n",
      "\n",
      "â€¢ Represent Textron Aviation on enterprise projects like an exit interview survey harmonization project.\n",
      "\n",
      "â€¢ Develop and maintain Qlikview, Power BI and Tableau Dashboards, to support senior leadership.\n",
      "\n",
      "â€¢ Uses Excel, R and SQL for data manipulation, analysis and reporting daily.\n",
      "\n",
      "â€¢ Developed VBAs to automate rewards planner reporting, reducing time from 2 days to under 1 hour. \n",
      "\n",
      "â€¢ Facilitate the integration of our HR change of status processes with a request tracking system.\n",
      "\n",
      "â€¢ Develop web scrapers in R to collect data from LinkedIn and other sites for sourcing.\n",
      "\n",
      "â€¢ Create a predictive model to forecast retirement and attrition for workforce planning.\n",
      "\n",
      "â€¢ Devised and implemented new exit interview survey, raising completion success rate from 25% to 70%.\n",
      "\n",
      "â€¢ Creates, maintains, and ensures quality assurance of key data sets, reports, and metrics.\n",
      "\n",
      "â€¢ Support leadership by providing data, workforce analysis and strategic planning recommendations.\n",
      "\n",
      "â€¢ Generate metrics, external benchmarks and labor market trends for business needs.\n",
      "\n",
      "    Advanced Analyst | Textron Aviation\t\t\t\t\t        February 2015 â€“ January 2017\n",
      "\n",
      "â€¢ Generate leads for the business development team by creating web scrapers for websites using R.\n",
      "\n",
      "â€¢ Build models with SQL in hadoop to analyze FAA records to determine when a plane had maintenance.\n",
      "\n",
      "â€¢ Maintain standard and customized queries that support the customer base.\n",
      "\n",
      "â€¢ Use statistical analysis to discover trends and forecast for potential buyers.\n",
      "\n",
      "â€¢ Program in R to reclassify all Salesforce account types.\n",
      "\n",
      "\n",
      "\n",
      "Recruiting Coordinator/Sourcer (Contract)| Precor Inc.\t\t                           Sep 2015 â€“ Dec 2015\n",
      "\n",
      "â€¢ Analyzed records and contacted vendors to generate reports of all contract labor at Precor.\n",
      "\n",
      "â€¢ Analyzed data from surveys and ad-hoc reports to create condensed readable presentations.\n",
      "\n",
      "â€¢ Created training documents for tools such as Pereless, Concur, and Workday.\n",
      "\n",
      "\n",
      "\n",
      "    Manager of Cashmere City Pool | City of Cashmere\t\t\t\t          May 2009 â€“ Sep 2015\n",
      "\n",
      "â€¢ Managed a team of 20 â€“ 30 employees.\n",
      "\n",
      "â€¢ Advised and developed safety procedures and policies for the facility.\n",
      "\n",
      "â€¢ Created proposals to change hours of operations and prices to increase revenues and cut costs.\n",
      "\n",
      "â€¢ Revised and implemented guideline specifications and pool processes based on analysis.\n",
      "\n",
      "â€¢ Wrote technical documents for development and implementation of new training strategies.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Education:\n",
      "\n",
      "\n",
      "\n",
      "Bellevue University, Bellevue, NE\n",
      "\n",
      "\tMasters of Science in Data Science| June 2018 â€“ November 2019 \n",
      "\n",
      "\tMasters of Science in Business Analytics | August 2015 â€“ March 2017 \n",
      "\n",
      "\n",
      "\n",
      "University of Washington, Seattle, WA\n",
      "\n",
      "\tBachelors of Arts in Mathematics | September 2012 â€“ June 2015\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "my_text = docx2txt.process(\"Chase Lemons Resume 6_17_2019.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content = []\n",
    "for line in my_text.splitlines():\n",
    "  if line != '':\n",
    "    clean_lines = line.strip().lower()\n",
    "    clean_lines2 = re.sub(r'[^a-zA-Z0-9\\._-]', ' ', clean_lines)\n",
    "    clean_lines2 = re.sub(r'\\s+', ' ', clean_lines2)\n",
    "    clean_lines2 = clean_lines2.strip()\n",
    "    content.append(clean_lines2)\n",
    "    \n",
    "jobs = df[\"Description\"].tolist()\n",
    "\n",
    "for i in range(len(jobs)):\n",
    "    jobs[i] = str(jobs[i]).strip().lower()\n",
    "\n",
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element)\n",
    "        result += \" \"\n",
    "    return result\n",
    "\n",
    "resume = concatenate_list_data(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(a,b):\n",
    "    calc = dot(a, b)/(norm(a)*norm(b))\n",
    "    return calc\n",
    "\n",
    "\n",
    "cos_sim_score = []\n",
    "included_list = ['NN','NNP', 'NNPS', 'NNS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "resume_tolk = word_tokenize(resume)\n",
    "l1 =[]\n",
    "\n",
    "tokenized_can_1 = []\n",
    "aa = nltk.pos_tag(resume_tolk)\n",
    "filt_sent = []\n",
    "for k in aa:\n",
    "    if k[1] in included_list:\n",
    "        filt_sent.append(k[0].lower())\n",
    "    tokenized_can_1.append(filt_sent)\n",
    "    X_set = set(tokenized_can_1[0])\n",
    "\n",
    "\n",
    "req_1 = df[\"Description\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_sim_score = []\n",
    "for i in range(len(jobs)):\n",
    "\n",
    "    job_des = jobs[i]\n",
    "  \n",
    "    # tokenization   \n",
    "    job_des_tolk = word_tokenize(job_des) \n",
    "\n",
    "    l1 =[];l2 =[]  \n",
    "\n",
    "    tokenized_req_1 = []\n",
    "    bb = nltk.pos_tag(job_des_tolk)\n",
    "    filt_sent = []\n",
    "    for k in bb:\n",
    "        if k[1] in included_list:\n",
    "            filt_sent.append(k[0].lower())\n",
    "    tokenized_req_1.append(filt_sent)\n",
    "    Y_set = set(tokenized_req_1[0])\n",
    "\n",
    "    # form a set containing keywords of both strings  \n",
    "    rvector = X_set.union(Y_set)  \n",
    "    for w in rvector: \n",
    "        if w in X_set: l1.append(1) # create a vector \n",
    "        else: l1.append(0) \n",
    "        if w in Y_set: l2.append(1) \n",
    "        else: l2.append(0) \n",
    "\n",
    "    cos = cos_sim(l1,l2)\n",
    "    cos_sim_score.append(cos)\n",
    "    df[\"des_res_similarity\"] = cos_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"indeed_job_dataset_with_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
