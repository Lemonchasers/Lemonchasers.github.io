{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 680\n",
    "## Assignment 8.1\n",
    "## Chase Lemons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indeed_job_dataset.csv\", sep =\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Queried_Salary</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Skill</th>\n",
       "      <th>No_of_Skills</th>\n",
       "      <th>Company</th>\n",
       "      <th>No_of_Reviews</th>\n",
       "      <th>No_of_Stars</th>\n",
       "      <th>...</th>\n",
       "      <th>MD</th>\n",
       "      <th>DC</th>\n",
       "      <th>NC</th>\n",
       "      <th>Other_states</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Other_industries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6a105f495c36a...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['SAP', 'SQL']</td>\n",
       "      <td>2</td>\n",
       "      <td>Express Scripts</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=86afd561ea8c6...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Machine Learning', 'R', 'SAS', 'SQL', 'Python']</td>\n",
       "      <td>5</td>\n",
       "      <td>Money Mart Financial Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e0aad317e6d45...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Data Mining', 'Data Management', 'R', 'SAS',...</td>\n",
       "      <td>9</td>\n",
       "      <td>comScore</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Graduate Studies Program - Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Certified Internal Auditor']</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>158.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fec647775a21e...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Statistical Software', 'Time Management', 'R...</td>\n",
       "      <td>7</td>\n",
       "      <td>Federal Reserve Bank of Dallas</td>\n",
       "      <td>495.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  Job_Title  \\\n",
       "0           0                             Data Scientist   \n",
       "1           1                             Data Scientist   \n",
       "2           2                             Data Scientist   \n",
       "3           3  Graduate Studies Program - Data Scientist   \n",
       "4           4                           Data Scientist I   \n",
       "\n",
       "                                                Link Queried_Salary  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=6a105f495c36a...         <80000   \n",
       "1  https://www.indeed.com/rc/clk?jk=86afd561ea8c6...         <80000   \n",
       "2  https://www.indeed.com/rc/clk?jk=e0aad317e6d45...         <80000   \n",
       "3  https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...         <80000   \n",
       "4  https://www.indeed.com/rc/clk?jk=fec647775a21e...         <80000   \n",
       "\n",
       "         Job_Type                                              Skill  \\\n",
       "0  data_scientist                                     ['SAP', 'SQL']   \n",
       "1  data_scientist  ['Machine Learning', 'R', 'SAS', 'SQL', 'Python']   \n",
       "2  data_scientist  ['Data Mining', 'Data Management', 'R', 'SAS',...   \n",
       "3  data_scientist                     ['Certified Internal Auditor']   \n",
       "4  data_scientist  ['Statistical Software', 'Time Management', 'R...   \n",
       "\n",
       "   No_of_Skills                         Company  No_of_Reviews  No_of_Stars  \\\n",
       "0             2                 Express Scripts         3301.0          3.3   \n",
       "1             5   Money Mart Financial Services            NaN          NaN   \n",
       "2             9                        comScore           62.0          3.5   \n",
       "3             1     Central Intelligence Agency          158.0          4.3   \n",
       "4             7  Federal Reserve Bank of Dallas          495.0          4.1   \n",
       "\n",
       "         ...         MD DC NC Other_states Consulting and Business Services  \\\n",
       "0        ...          0  0  0            1                                0   \n",
       "1        ...          0  0  0            0                                0   \n",
       "2        ...          0  0  0            1                                0   \n",
       "3        ...          0  1  0            0                                0   \n",
       "4        ...          0  0  0            0                                0   \n",
       "\n",
       "  Internet and Software  Banks and Financial Services  Health Care  Insurance  \\\n",
       "0                     0                             0            1          0   \n",
       "1                     0                             0            0          0   \n",
       "2                     0                             0            0          0   \n",
       "3                     0                             0            0          0   \n",
       "4                     0                             1            0          0   \n",
       "\n",
       "   Other_industries  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chase H. Lemons\n",
      "\n",
      "\tAdvanced Analyst  \n",
      "\n",
      "\t509.668.8358  \n",
      "\n",
      "\tClemons_12@hotmail.com\n",
      "\n",
      "\tGoal oriented professional with 5+ years of experience in big data and advanced analytics across multiple functions. Seeking a position to utilize and enhance my leadership, analytics and developer skills. Extremely passionate about analytics, strategy and process improvement.\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Work Experience:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sr. Advanced Analyst | Textron Aviation\t            \t\t\t\t         October 2018 - Present\n",
      "\n",
      "• Actively provide strategy for overall analytics roadmap and operating model for Textron Aviation.\n",
      "\n",
      "• Lead a Tableau proof of concept with the business.\n",
      "\n",
      "• Develop dashboards for multiple business areas utilizing Tableau, Qlikview, and Power BI.\n",
      "\n",
      "• Ensure ETL processes in and out of the enterprise data warehouse perform successfully. \n",
      "\n",
      "• Uses a combination of R, Python and SQL for data manipulation, analysis and reporting daily.\n",
      "\n",
      "• Implemented a model to identify parts that needed price adjustment based on ecommerce data.\n",
      "\n",
      "• Translates high-level business requirements into functional specifications and manages changes.\n",
      "\n",
      "• Develop metrics of utilization of IT tools and systems.\n",
      "\n",
      "• Team lead for business intelligence and predictive data models.\n",
      "\n",
      "• Developed a candidate percent match tool for recruiters to help with efficiency.\n",
      "\n",
      "\n",
      "\n",
      "HR Analyst | Textron Aviation\t           \t\t           Dec 2015 – February 2016, January 2017 - Present\n",
      "\n",
      "• Be a lead for team members with less experience in the analytics space.\n",
      "\n",
      "• Perform technology overviews and provide recommendations on BI, Analytics tools, and other HR tools.\n",
      "\n",
      "• Represent Textron Aviation on enterprise projects like an exit interview survey harmonization project.\n",
      "\n",
      "• Develop and maintain Qlikview, Power BI and Tableau Dashboards, to support senior leadership.\n",
      "\n",
      "• Uses Excel, R and SQL for data manipulation, analysis and reporting daily.\n",
      "\n",
      "• Developed VBAs to automate rewards planner reporting, reducing time from 2 days to under 1 hour. \n",
      "\n",
      "• Facilitate the integration of our HR change of status processes with a request tracking system.\n",
      "\n",
      "• Develop web scrapers in R to collect data from LinkedIn and other sites for sourcing.\n",
      "\n",
      "• Create a predictive model to forecast retirement and attrition for workforce planning.\n",
      "\n",
      "• Devised and implemented new exit interview survey, raising completion success rate from 25% to 70%.\n",
      "\n",
      "• Creates, maintains, and ensures quality assurance of key data sets, reports, and metrics.\n",
      "\n",
      "• Support leadership by providing data, workforce analysis and strategic planning recommendations.\n",
      "\n",
      "• Generate metrics, external benchmarks and labor market trends for business needs.\n",
      "\n",
      "    Advanced Analyst | Textron Aviation\t\t\t\t\t        February 2015 – January 2017\n",
      "\n",
      "• Generate leads for the business development team by creating web scrapers for websites using R.\n",
      "\n",
      "• Build models with SQL in hadoop to analyze FAA records to determine when a plane had maintenance.\n",
      "\n",
      "• Maintain standard and customized queries that support the customer base.\n",
      "\n",
      "• Use statistical analysis to discover trends and forecast for potential buyers.\n",
      "\n",
      "• Program in R to reclassify all Salesforce account types.\n",
      "\n",
      "\n",
      "\n",
      "Recruiting Coordinator/Sourcer (Contract)| Precor Inc.\t\t                           Sep 2015 – Dec 2015\n",
      "\n",
      "• Analyzed records and contacted vendors to generate reports of all contract labor at Precor.\n",
      "\n",
      "• Analyzed data from surveys and ad-hoc reports to create condensed readable presentations.\n",
      "\n",
      "• Created training documents for tools such as Pereless, Concur, and Workday.\n",
      "\n",
      "\n",
      "\n",
      "    Manager of Cashmere City Pool | City of Cashmere\t\t\t\t          May 2009 – Sep 2015\n",
      "\n",
      "• Managed a team of 20 – 30 employees.\n",
      "\n",
      "• Advised and developed safety procedures and policies for the facility.\n",
      "\n",
      "• Created proposals to change hours of operations and prices to increase revenues and cut costs.\n",
      "\n",
      "• Revised and implemented guideline specifications and pool processes based on analysis.\n",
      "\n",
      "• Wrote technical documents for development and implementation of new training strategies.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Education:\n",
      "\n",
      "\n",
      "\n",
      "Bellevue University, Bellevue, NE\n",
      "\n",
      "\tMasters of Science in Data Science| June 2018 – November 2019 \n",
      "\n",
      "\tMasters of Science in Business Analytics | August 2015 – March 2017 \n",
      "\n",
      "\n",
      "\n",
      "University of Washington, Seattle, WA\n",
      "\n",
      "\tBachelors of Arts in Mathematics | September 2012 – June 2015\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "my_text = docx2txt.process(\"Chase Lemons Resume 6_17_2019.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content = []\n",
    "for line in my_text.splitlines():\n",
    "  if line != '':\n",
    "    clean_lines = line.strip().lower()\n",
    "    clean_lines2 = re.sub(r'[^a-zA-Z0-9\\._-]', ' ', clean_lines)\n",
    "    clean_lines2 = re.sub(r'\\s+', ' ', clean_lines2)\n",
    "    clean_lines2 = clean_lines2.strip()\n",
    "    content.append(clean_lines2)\n",
    "    \n",
    "jobs = df[\"Description\"].tolist()\n",
    "\n",
    "for i in range(len(jobs)):\n",
    "    jobs[i] = str(jobs[i]).strip().lower()\n",
    "\n",
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element)\n",
    "        result += \" \"\n",
    "    return result\n",
    "\n",
    "resume = concatenate_list_data(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(a,b):\n",
    "    calc = dot(a, b)/(norm(a)*norm(b))\n",
    "    return calc\n",
    "\n",
    "\n",
    "cos_sim_score = []\n",
    "included_list = ['NN','NNP', 'NNPS', 'NNS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "resume_tolk = word_tokenize(resume)\n",
    "l1 =[]\n",
    "\n",
    "tokenized_can_1 = []\n",
    "aa = nltk.pos_tag(resume_tolk)\n",
    "filt_sent = []\n",
    "for k in aa:\n",
    "    if k[1] in included_list:\n",
    "        filt_sent.append(k[0].lower())\n",
    "    tokenized_can_1.append(filt_sent)\n",
    "    X_set = set(tokenized_can_1[0])\n",
    "\n",
    "\n",
    "req_1 = df[\"Description\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_sim_score = []\n",
    "for i in range(len(jobs)):\n",
    "\n",
    "    job_des = jobs[i]\n",
    "  \n",
    "    # tokenization   \n",
    "    job_des_tolk = word_tokenize(job_des) \n",
    "\n",
    "    l1 =[];l2 =[]  \n",
    "\n",
    "    tokenized_req_1 = []\n",
    "    bb = nltk.pos_tag(job_des_tolk)\n",
    "    filt_sent = []\n",
    "    for k in bb:\n",
    "        if k[1] in included_list:\n",
    "            filt_sent.append(k[0].lower())\n",
    "    tokenized_req_1.append(filt_sent)\n",
    "    Y_set = set(tokenized_req_1[0])\n",
    "\n",
    "    # form a set containing keywords of both strings  \n",
    "    rvector = X_set.union(Y_set)  \n",
    "    for w in rvector: \n",
    "        if w in X_set: l1.append(1) # create a vector \n",
    "        else: l1.append(0) \n",
    "        if w in Y_set: l2.append(1) \n",
    "        else: l2.append(0) \n",
    "\n",
    "    cos = cos_sim(l1,l2)\n",
    "    cos_sim_score.append(cos)\n",
    "    df[\"des_res_similarity\"] = cos_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"indeed_job_dataset_with_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
